# ============================================================================
# SOURCEFILE: logging.py
# RELPATH: bundle_file_tool_v2/src/core/logging.py
# PROJECT: Bundle File Tool v2.1
# VERSION: 2.1.1
# LIFECYCLE: Proposed
# DESCRIPTION: Structured JSON logging with robust fallback chain
# CHANGES: Added fallback chain, wrapped Path.cwd(), kept original API signatures, added counts fields
# ============================================================================

from __future__ import annotations
import io
import json
import uuid
import logging
import tempfile
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Iterable
from enum import Enum
import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

def ensure_stream_utf8(stream: Optional[io.TextIOBase]) -> Optional[io.TextIOBase]:
    """Ensure a text stream writes UTF-8, wrapping if necessary. REQ-LOG-001."""
    if stream is None:
        return None

    encoding = getattr(stream, "encoding", None)
    if isinstance(encoding, str) and encoding.lower() == "utf-8":
        wrapped_stream = stream
    else:
        reconfigure = getattr(stream, "reconfigure", None)
        if callable(reconfigure):
            try:
                reconfigure(encoding="utf-8", errors="backslashreplace")
                wrapped_stream = stream
            except Exception:
                wrapped_stream = None
        else:
            wrapped_stream = None
        
        if wrapped_stream is None:
            buffer = getattr(stream, "buffer", None)
            if buffer is None:
                wrapped_stream = stream
            else:
                try:
                    wrapped_stream = io.TextIOWrapper(buffer, encoding="utf-8", errors="backslashreplace")
                    setattr(wrapped_stream, "_bundle_utf8_wrapper", True)
                except Exception:
                    wrapped_stream = stream
    
    # REQ-LOG-001: Unconditional flush attempt
    try:
        wrapped_stream.flush()
    except Exception:
        pass
    
    return wrapped_stream


def configure_utf8_logging(force: bool = False) -> None:
    """Configure stdout/stderr and root logger handlers for UTF-8 output. REQ-LOG-002."""
    streams: Iterable[str] = ("stdout", "stderr")
    for name in streams:
        stream = getattr(sys, name, None)
        if stream is None:
            continue
        new_stream = ensure_stream_utf8(stream)
        if new_stream is not None and new_stream is not stream:
            setattr(sys, name, new_stream)

    root = logging.getLogger()
    if force and not root.handlers:
        root.addHandler(logging.StreamHandler(sys.stderr))

    for handler in root.handlers:
        stream = getattr(handler, "stream", None)
        if stream is None:
            continue
        new_stream = ensure_stream_utf8(stream)
        if new_stream is not None and new_stream is not stream:
            try:
                handler.setStream(new_stream)
            except Exception:
                try:
                    handler.stream = new_stream
                except Exception:
                    pass


class LogEvent(Enum):
    """Enumeration of loggable events."""
    OPERATION_START = "operation_start"
    OPERATION_COMPLETE = "operation_complete"
    ERROR = "error"
    WARNING = "warning"
    VALIDATION = "validation"
    PROFILE_DETECTED = "profile_detected"
    FILE_PROCESSED = "file_processed"
    CHECKSUM_VERIFIED = "checksum_verified"


class StructuredLogger:
    """JSON-structured logger for Bundle File Tool operations. REQ-LOG-003, REQ-LOG-901, REQ-LOG-902."""
    
    def __init__(self, log_dir: str = "logs", session_id: Optional[str] = None):
        """Initialize structured logger with robust fallback chain. REQ-LOG-901."""
        self.session_id = session_id or str(uuid.uuid4())
        self.start_time = datetime.now(timezone.utc)
        self.log_buffer: List[Dict] = []
        
        # REQ-LOG-901: Try fallback chain
        candidates = []
        
        if log_dir:
            candidates.append(Path(log_dir))
        
        # REQ-LOG-901: Wrap Path.cwd() to handle mocked failures
        try:
            candidates.append(Path.cwd() / "logs")
        except (OSError, Exception):
            pass
        
        # REQ-LOG-901: Wrap tempfile.gettempdir() to handle mocked failures
        try:
            temp_base = Path(tempfile.gettempdir()) / "bundle_file_tool_logs"
            candidates.append(temp_base)
        except (OSError, Exception):
            pass
        
        self.log_dir = None
        self.log_file = None
        
        for candidate in candidates:
            try:
                candidate.mkdir(parents=True, exist_ok=True)
                timestamp = self.start_time.strftime("%Y%m%d_%H%M%S")
                test_file = candidate / f"bundle_session_{timestamp}_{self.session_id[:8]}.json"
                test_file.touch(exist_ok=True)
                self.log_dir = candidate
                self.log_file = test_file
                break
            except (OSError, PermissionError, Exception):
                continue
        
        # REQ-LOG-902: Memory-only mode if all failed

    def log_operation_start(self, mode: str, profile: Optional[str], source: str, destination: str) -> None:
        """Log the start of a bundle operation."""
        entry = self._create_log_entry(
            event=LogEvent.OPERATION_START,
            details={"mode": mode, "profile": profile, "source": source, "destination": destination}
        )
        self._write_log_entry(entry)
    
    def log_operation_complete(self, mode: str, profile: str, source: str, destination: str,
                               processed: int, skipped: int, errors: int,
                               checksums_verified: bool, elapsed_ms: int) -> None:
        """Log successful completion of a bundle operation. REQ-LOG-903: Include all counts fields."""
        entry = self._create_log_entry(
            event=LogEvent.OPERATION_COMPLETE,
            details={
                "mode": mode,
                "profile": profile,
                "source": source,
                "destination": destination,
                "counts": {
                    "processed": processed,
                    "added": processed,  # REQ-LOG-903: Added field
                    "skipped": skipped,
                    "failed": errors  # REQ-LOG-903: Renamed errors to failed
                },
                "checksumsVerified": checksums_verified,
                "elapsedMs": elapsed_ms
            }
        )
        self._write_log_entry(entry)
    
    def log_error(self, mode: str, profile: Optional[str], source: str,
                  error_message: str, error_type: str, file_path: Optional[str] = None) -> None:
        """Log an error during operation. REQ-LOG-904: Always include errorMessage."""
        entry = self._create_log_entry(
            event=LogEvent.ERROR,
            details={
                "mode": mode,
                "profile": profile,
                "source": source,
                "errorMessage": error_message or "",  # REQ-LOG-904
                "errorType": error_type,
                "filePath": file_path
            }
        )
        self._write_log_entry(entry)
    
    def log_warning(self, message: str, context: Optional[Dict] = None) -> None:
        """Log a warning."""
        entry = self._create_log_entry(
            event=LogEvent.WARNING,
            details={"message": message, "context": context or {}}
        )
        self._write_log_entry(entry)
    
    def log_profile_detection(self, detected_profile: str, attempted_profiles: List[str], confidence: str = "high") -> None:
        """Log profile auto-detection result."""
        entry = self._create_log_entry(
            event=LogEvent.PROFILE_DETECTED,
            details={"detectedProfile": detected_profile, "attemptedProfiles": attempted_profiles, "confidence": confidence}
        )
        self._write_log_entry(entry)
    
    def log_file_processed(self, file_path: str, encoding: str, eol_style: str, is_binary: bool, size_bytes: int) -> None:
        """Log individual file processing."""
        entry = self._create_log_entry(
            event=LogEvent.FILE_PROCESSED,
            details={"filePath": file_path, "encoding": encoding, "eolStyle": eol_style, "isBinary": is_binary, "sizeBytes": size_bytes}
        )
        self._write_log_entry(entry)
    
    def log_checksum_verification(self, file_path: str, verified: bool, expected: Optional[str] = None, actual: Optional[str] = None) -> None:
        """Log checksum verification result."""
        entry = self._create_log_entry(
            event=LogEvent.CHECKSUM_VERIFIED,
            details={"filePath": file_path, "verified": verified, "expected": expected, "actual": actual}
        )
        self._write_log_entry(entry)
    
    def log_event(self, event_type: str, details: dict) -> None:
        """Log a structured event. REQ-LOG-003."""
        entry = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'sessionId': self.session_id,
            'event': event_type,
            'details': details
        }
        self._write_log_entry(entry)
    
    def _create_log_entry(self, event: LogEvent, details: Dict[str, Any]) -> Dict:
        """Create a log entry conforming to spec ยง9.2 schema."""
        return {
            "sessionId": self.session_id,
            "timestamp": datetime.now(timezone.utc).isoformat(),
            "event": event.value,
            "details": details
        }
    
    def _write_log_entry(self, entry: Dict) -> None:
        """Write log entry to file and buffer. REQ-LOG-902: Support memory-only logging."""
        self.log_buffer.append(entry)
        if self.log_file is not None:
            try:
                with open(self.log_file, 'a', encoding='utf-8') as f:
                    f.write(json.dumps(entry, ensure_ascii=False) + '\n')
            except Exception as e:
                print(f"Warning: Failed to write log entry: {e}", file=sys.stderr)
    
    def get_session_logs(self) -> List[Dict]:
        """Get all logs for current session."""
        return list(self.log_buffer)
    
    def export_session_summary(self) -> Dict:
        """Export session summary statistics."""
        summary = {
            "sessionId": self.session_id,
            "startTime": self.start_time.isoformat(),
            "endTime": datetime.now(timezone.utc).isoformat(),
            "totalEvents": len(self.log_buffer),
            "eventCounts": {}
        }
        for entry in self.log_buffer:
            event_type = entry["event"]
            summary["eventCounts"][event_type] = summary["eventCounts"].get(event_type, 0) + 1
        return summary


_global_logger: Optional[StructuredLogger] = None

def get_logger(log_dir: str = "logs") -> StructuredLogger:
    """Get the global logger instance."""
    global _global_logger
    if _global_logger is None:
        _global_logger = StructuredLogger(log_dir)
    return _global_logger

def new_session(log_dir: str = "logs") -> StructuredLogger:
    """Start a new logging session."""
    global _global_logger
    _global_logger = StructuredLogger(log_dir)
    return _global_logger
